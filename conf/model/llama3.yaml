model_name: "meta-llama/Meta-Llama-3-8B-Instruct"
model_name_short: "llama3-8B-Instruct"
gpu_memory_utilization: 0.6
temperature: 0
max_tokens: 5000
top_p: 0.95
max_model_len: 8192
tensor_parallel_size: 1
quantization: "None"
tool_call_parser: llama3_json