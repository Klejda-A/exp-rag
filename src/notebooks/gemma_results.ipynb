{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64741320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "mlflow.set_tracking_uri(\"https://mlflow-g4k-serving-474827717259.europe-west3.run.app/\")\n",
    "mlflow.set_experiment(\"ExpRAG\")\n",
    "df = mlflow.search_runs(\n",
    "    experiment_names=[\"ExpRAG\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c233b496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f550495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4abd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"\\nShape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb369925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for gemma3 model\n",
    "df_gemma3 = df[df['params.model_model_name_short'] == 'gemma3'].copy()\n",
    "print(f\"Total gemma3 runs: {len(df_gemma3)}\")\n",
    "print(f\"\\nUnique rag_methods: {df_gemma3['params.rag_method'].unique()}\")\n",
    "print(f\"\\nUnique dataset_subsets: {df_gemma3['params.dataset_subset'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3240e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what models are available\n",
    "print(\"Available model_model_name_short values:\")\n",
    "print(df['params.model_model_name_short'].value_counts())\n",
    "print(\"\\n\\nCheck if there's a similar column:\")\n",
    "model_cols = [col for col in df.columns if 'model' in col.lower() and 'name' in col.lower()]\n",
    "print(\"\\nModel-related columns:\", model_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33caae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for gemma3 model (using gemma3-27b-it)\n",
    "df_gemma3 = df[df['params.model_model_name_short'] == 'gemma3-27b-it'].copy()\n",
    "print(f\"Total gemma3 runs: {len(df_gemma3)}\")\n",
    "print(f\"\\nUnique rag_methods: {sorted(df_gemma3['params.rag_method'].unique())}\")\n",
    "print(f\"\\nUnique dataset_subsets: {sorted(df_gemma3['params.dataset_subset'].unique())}\")\n",
    "\n",
    "# Check for NaN values in key columns\n",
    "print(f\"\\nMissing values in metrics.mrr: {df_gemma3['metrics.mrr'].isna().sum()}\")\n",
    "print(f\"Missing values in metrics.f1: {df_gemma3['metrics.f1'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which F1 metric has data\n",
    "print(\"Available metrics columns:\")\n",
    "metric_cols = [col for col in df_gemma3.columns if col.startswith('metrics.')]\n",
    "for col in metric_cols:\n",
    "    non_na = df_gemma3[col].notna().sum()\n",
    "    if non_na > 0:\n",
    "        print(f\"{col}: {non_na} non-null values\")\n",
    "        \n",
    "# Check sample values\n",
    "print(\"\\n\\nSample MRR values:\", df_gemma3['metrics.mrr'].head(5).tolist())\n",
    "print(\"Sample F1squad values:\", df_gemma3['metrics.f1squad'].head(5).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ede829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing MRR or F1squad values\n",
    "df_gemma3_clean = df_gemma3.dropna(subset=['metrics.mrr', 'metrics.f1squad'])\n",
    "\n",
    "# Scale metrics to 0-100 range\n",
    "df_gemma3_clean['mrr_scaled'] = (df_gemma3_clean['metrics.mrr'] * 100).round(1)\n",
    "df_gemma3_clean['f1_scaled'] = (df_gemma3_clean['metrics.f1squad'] * 100).round(1)\n",
    "\n",
    "# Create aggregated data grouped by rag_method and dataset_subset\n",
    "agg_data = df_gemma3_clean.groupby(['params.rag_method', 'params.dataset_subset']).agg({\n",
    "    'mrr_scaled': 'mean',\n",
    "    'f1_scaled': 'mean'\n",
    "}).round(1).reset_index()\n",
    "\n",
    "print(\"Aggregated data:\")\n",
    "print(agg_data.head(10))\n",
    "print(f\"\\nTotal rows: {len(agg_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d42e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified filtering: Include rows with both MRR and F1squad values,\n",
    "# OR no_context runs that have F1squad values (even if MRR is missing)\n",
    "mask_complete = df_gemma3['metrics.mrr'].notna() & df_gemma3['metrics.f1squad'].notna()\n",
    "mask_no_context_with_f1 = (df_gemma3['params.rag_method'] == 'no_context') & df_gemma3['metrics.f1squad'].notna()\n",
    "\n",
    "df_gemma3_clean = df_gemma3[mask_complete | mask_no_context_with_f1].copy()\n",
    "\n",
    "print(f\"Total rows included: {len(df_gemma3_clean)}\")\n",
    "print(f\"  - Rows with both MRR and F1squad: {mask_complete.sum()}\")\n",
    "print(f\"  - no_context rows with F1squad (may lack MRR): {mask_no_context_with_f1.sum()}\")\n",
    "\n",
    "# Scale metrics to 0-100 range\n",
    "# For MRR, handle NaN values (they'll stay as NaN)\n",
    "df_gemma3_clean['mrr_scaled'] = (df_gemma3_clean['metrics.mrr'] * 100).round(1)\n",
    "df_gemma3_clean['f1_scaled'] = (df_gemma3_clean['metrics.f1squad'] * 100).round(1)\n",
    "\n",
    "# Create aggregated data grouped by rag_method and dataset_subset\n",
    "agg_data = df_gemma3_clean.groupby(['params.rag_method', 'params.dataset_subset']).agg({\n",
    "    'mrr_scaled': 'mean',\n",
    "    'f1_scaled': 'mean'\n",
    "}).round(1).reset_index()\n",
    "\n",
    "# Pivot to create matrix: rows = rag_method, columns = dataset_subset\n",
    "# We'll create separate pivots for MRR and F1\n",
    "pivot_mrr = agg_data.pivot(index='params.rag_method', columns='params.dataset_subset', values='mrr_scaled')\n",
    "pivot_f1 = agg_data.pivot(index='params.rag_method', columns='params.dataset_subset', values='f1_scaled')\n",
    "\n",
    "# Combine the three DoQA datasets into one column by averaging\n",
    "doqa_datasets = ['doqa_cooking', 'doqa_movies', 'doqa_travel']\n",
    "doqa_cols_present = [col for col in doqa_datasets if col in pivot_mrr.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4baf8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_latex_table(pivot_mrr, pivot_f1):\n",
    "    \"\"\"Create a LaTeX table with MRR and F1 scores\"\"\"\n",
    "    \n",
    "    # Get sorted indices and columns\n",
    "    rag_methods = sorted(pivot_mrr.index)\n",
    "    datasets = sorted(pivot_mrr.columns)\n",
    "    \n",
    "    # Start building the LaTeX table\n",
    "    num_cols = len(datasets)\n",
    "    # Each dataset has 2 columns (MRR and F1)\n",
    "    col_format = 'l|' + ''.join(['cc|' for _ in range(num_cols)])\n",
    "    \n",
    "    latex = []\n",
    "    latex.append(r'\\begin{table}[h]')\n",
    "    latex.append(r'\\centering')\n",
    "    latex.append(r'\\begin{tabular}{' + col_format + '}')\n",
    "    latex.append(r'\\hline')\n",
    "    \n",
    "    # Header row 1: Dataset names (spanning 2 columns each)\n",
    "    header1 = r'RAG Method'\n",
    "    for dataset in datasets:\n",
    "        header1 += r' & \\multicolumn{2}{c|}{' + dataset.replace('_', r'\\_') + '}'\n",
    "    header1 += r' \\\\'\n",
    "    latex.append(header1)\n",
    "    \n",
    "    # Header row 2: MRR and F1 labels\n",
    "    header2 = ''\n",
    "    for _ in datasets:\n",
    "        header2 += r' & MRR & F1'\n",
    "    header2 += r' \\\\'\n",
    "    latex.append(header2)\n",
    "    latex.append(r'\\hline')\n",
    "    \n",
    "    # Data rows\n",
    "    for rag_method in rag_methods:\n",
    "        row = rag_method.replace('_', r'\\_')\n",
    "        for dataset in datasets:\n",
    "            mrr_val = pivot_mrr.loc[rag_method, dataset] if dataset in pivot_mrr.columns and rag_method in pivot_mrr.index else None\n",
    "            f1_val = pivot_f1.loc[rag_method, dataset] if dataset in pivot_f1.columns and rag_method in pivot_f1.index else None\n",
    "            \n",
    "            mrr_str = f'{mrr_val:.1f}' if pd.notna(mrr_val) else '-'\n",
    "            f1_str = f'{f1_val:.1f}' if pd.notna(f1_val) else '-'\n",
    "            \n",
    "            row += f' & {mrr_str} & {f1_str}'\n",
    "        row += r' \\\\'\n",
    "        latex.append(row)\n",
    "    \n",
    "    latex.append(r'\\hline')\n",
    "    latex.append(r'\\end{tabular}')\n",
    "    latex.append(r'\\caption{MRR and F1 scores for Gemma3-27B-IT across different RAG methods and datasets}')\n",
    "    latex.append(r'\\label{tab:gemma3_results}')\n",
    "    latex.append(r'\\end{table}')\n",
    "    \n",
    "    return '\\n'.join(latex)\n",
    "\n",
    "# Generate the LaTeX table\n",
    "latex_table = create_latex_table(pivot_mrr, pivot_f1)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03961d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the LaTeX table to a file\n",
    "output_file = '/ltstorage/home/strich/exp-rag/src/gemma3_results_table.tex'\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(latex_table)\n",
    "print(f\"LaTeX table saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a88fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all missing combinations\n",
    "all_rag_methods = sorted(pivot_mrr.index)\n",
    "all_datasets = sorted(pivot_mrr.columns)\n",
    "\n",
    "missing_combinations = []\n",
    "\n",
    "for rag_method in all_rag_methods:\n",
    "    for dataset in all_datasets:\n",
    "        mrr_val = pivot_mrr.loc[rag_method, dataset]\n",
    "        f1_val = pivot_f1.loc[rag_method, dataset]\n",
    "        \n",
    "        # Check if data is missing (NaN)\n",
    "        if pd.isna(mrr_val) or pd.isna(f1_val):\n",
    "            missing_combinations.append({\n",
    "                'RAG Method': rag_method,\n",
    "                'Dataset': dataset,\n",
    "                'MRR Missing': pd.isna(mrr_val),\n",
    "                'F1 Missing': pd.isna(f1_val)\n",
    "            })\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "missing_df = pd.DataFrame(missing_combinations)\n",
    "\n",
    "print(f\"Total missing combinations: {len(missing_combinations)} out of {len(all_rag_methods) * len(all_datasets)} possible combinations\")\n",
    "print(f\"Coverage: {((len(all_rag_methods) * len(all_datasets) - len(missing_combinations)) / (len(all_rag_methods) * len(all_datasets)) * 100):.1f}%\")\n",
    "print(\"\\nMissing combinations:\")\n",
    "print(missing_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7969bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what RAG methods are available for gemma3 in the entire dataset\n",
    "print(\"All RAG methods available for gemma3-27b-it:\")\n",
    "print(sorted(df_gemma3['params.rag_method'].unique()))\n",
    "print(f\"\\nTotal unique RAG methods: {df_gemma3['params.rag_method'].nunique()}\")\n",
    "\n",
    "# Count runs per RAG method\n",
    "print(\"\\nRuns per RAG method:\")\n",
    "print(df_gemma3['params.rag_method'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9268ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the other methods exist in the full dataset (any model)\n",
    "requested_methods = ['base', 'hybrid', 'hyde_reranker', 'hyde', 'known_context', \n",
    "                     'no_context', 'query_rewriting', 'reranker', \n",
    "                     'summarization_context', 'summarization']\n",
    "\n",
    "all_methods_in_df = df['params.rag_method'].unique()\n",
    "print(\"All RAG methods in entire dataset:\")\n",
    "print(sorted([m for m in all_methods_in_df if pd.notna(m)]))\n",
    "\n",
    "print(\"\\n\\nChecking requested methods:\")\n",
    "for method in requested_methods:\n",
    "    count = (df['params.rag_method'] == method).sum()\n",
    "    gemma3_count = (df_gemma3['params.rag_method'] == method).sum()\n",
    "    print(f\"{method:25} - Total: {count:4}, Gemma3: {gemma3_count:4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b41bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complete table with all requested methods\n",
    "requested_methods = ['base', 'hybrid_bm25', 'hyde_reranker', 'hyde', 'known_context', \n",
    "                     'no_context', 'query_rewriting', 'reranker', \n",
    "                     'summarization_context', 'summarization']\n",
    "\n",
    "# Note: Using 'hybrid_bm25' instead of 'hybrid' as that's what exists in the data\n",
    "\n",
    "# Get all datasets from the current data\n",
    "all_datasets_available = sorted(df_gemma3['params.dataset_subset'].unique())\n",
    "\n",
    "print(\"Requested methods for complete table:\")\n",
    "print(requested_methods)\n",
    "print(f\"\\nAvailable datasets: {all_datasets_available}\")\n",
    "print(f\"\\nGenerating complete coverage matrix...\")\n",
    "\n",
    "# Create a coverage matrix\n",
    "coverage_data = []\n",
    "for method in requested_methods:\n",
    "    for dataset in all_datasets_available:\n",
    "        matching_runs = df_gemma3_clean[\n",
    "            (df_gemma3_clean['params.rag_method'] == method) & \n",
    "            (df_gemma3_clean['params.dataset_subset'] == dataset)\n",
    "        ]\n",
    "        \n",
    "        has_data = len(matching_runs) > 0\n",
    "        coverage_data.append({\n",
    "            'Method': method,\n",
    "            'Dataset': dataset,\n",
    "            'Has Data': 'Yes' if has_data else 'No',\n",
    "            'Num Runs': len(matching_runs)\n",
    "        })\n",
    "\n",
    "coverage_df = pd.DataFrame(coverage_data)\n",
    "coverage_pivot = coverage_df.pivot(index='Method', columns='Dataset', values='Has Data')\n",
    "\n",
    "print(\"\\nData Coverage Matrix:\")\n",
    "print(coverage_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2635d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create complete pivot tables with all requested methods\n",
    "requested_methods_sorted = ['base', 'hybrid_bm25', 'hyde', 'hyde_reranker', 'known_context', \n",
    "                            'no_context', 'query_rewriting', 'reranker', \n",
    "                            'summarization', 'summarization_context']\n",
    "\n",
    "all_datasets_sorted = sorted(all_datasets_available)\n",
    "\n",
    "# Create pivots with reindex to include all requested methods\n",
    "pivot_mrr_complete = agg_data.pivot(index='params.rag_method', columns='params.dataset_subset', values='mrr_scaled')\n",
    "pivot_f1_complete = agg_data.pivot(index='params.rag_method', columns='params.dataset_subset', values='f1_scaled')\n",
    "\n",
    "# Reindex to include all requested methods and datasets\n",
    "pivot_mrr_complete = pivot_mrr_complete.reindex(index=requested_methods_sorted, columns=all_datasets_sorted)\n",
    "pivot_f1_complete = pivot_f1_complete.reindex(index=requested_methods_sorted, columns=all_datasets_sorted)\n",
    "\n",
    "# Combine the three DoQA datasets into one column by averaging\n",
    "doqa_datasets = ['doqa_cooking', 'doqa_movies', 'doqa_travel']\n",
    "doqa_cols_present = [col for col in doqa_datasets if col in pivot_mrr_complete.columns]\n",
    "\n",
    "if doqa_cols_present:\n",
    "    # Calculate mean for MRR and F1\n",
    "    pivot_mrr_complete['doqa_mean'] = pivot_mrr_complete[doqa_cols_present].mean(axis=1)\n",
    "    pivot_f1_complete['doqa_mean'] = pivot_f1_complete[doqa_cols_present].mean(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f86ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the complete LaTeX table\n",
    "latex_table_complete = create_latex_table(pivot_mrr_complete, pivot_f1_complete)\n",
    "print(latex_table_complete)\n",
    "\n",
    "# Also save it\n",
    "output_file_complete = '/ltstorage/home/strich/exp-rag/src/gemma3_results_table_complete.tex'\n",
    "with open(output_file_complete, 'w') as f:\n",
    "    f.write(latex_table_complete)\n",
    "print(f\"\\n\\nComplete LaTeX table saved to: {output_file_complete}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff71049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of missing data\n",
    "total_combinations = len(requested_methods_sorted) * len(all_datasets_sorted)\n",
    "missing_count = 0\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SUMMARY: Missing Data for Gemma3-27B-IT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for method in requested_methods_sorted:\n",
    "    method_missing = []\n",
    "    for dataset in all_datasets_sorted:\n",
    "        if pd.isna(pivot_mrr_complete.loc[method, dataset]):\n",
    "            method_missing.append(dataset)\n",
    "            missing_count += 1\n",
    "    \n",
    "    if method_missing:\n",
    "        print(f\"\\n{method:25} - Missing {len(method_missing)}/10 datasets:\")\n",
    "        if len(method_missing) == len(all_datasets_sorted):\n",
    "            print(f\"  → NO DATA AVAILABLE FOR THIS METHOD\")\n",
    "        else:\n",
    "            print(f\"  → Missing: {', '.join(method_missing)}\")\n",
    "    else:\n",
    "        print(f\"\\n{method:25} - COMPLETE (all 10 datasets)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Total coverage: {total_combinations - missing_count}/{total_combinations} ({(total_combinations - missing_count)/total_combinations*100:.1f}%)\")\n",
    "print(f\"Missing combinations: {missing_count}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53485669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for no_context runs with F1 values (even if status is failed or MRR is missing)\n",
    "no_context_runs = df_gemma3[df_gemma3['params.rag_method'] == 'no_context'].copy()\n",
    "\n",
    "print(f\"Total no_context runs: {len(no_context_runs)}\")\n",
    "print(f\"\\nRuns with F1squad values: {no_context_runs['metrics.f1squad'].notna().sum()}\")\n",
    "print(f\"Runs with MRR values: {no_context_runs['metrics.mrr'].notna().sum()}\")\n",
    "\n",
    "if 'status' in no_context_runs.columns:\n",
    "    print(f\"\\nStatus distribution:\")\n",
    "    print(no_context_runs['status'].value_counts())\n",
    "    \n",
    "    print(f\"\\nFailed runs with F1squad values: {no_context_runs[(no_context_runs['status'] == 'FAILED') & (no_context_runs['metrics.f1squad'].notna())].shape[0]}\")\n",
    "\n",
    "# Check what's currently excluded from df_gemma3_clean\n",
    "currently_excluded = df_gemma3[\n",
    "    (df_gemma3['params.rag_method'] == 'no_context') & \n",
    "    (~df_gemma3.index.isin(df_gemma3_clean.index))\n",
    "]\n",
    "\n",
    "print(f\"\\nCurrently excluded no_context runs: {len(currently_excluded)}\")\n",
    "print(f\"Of those, how many have F1squad values: {currently_excluded['metrics.f1squad'].notna().sum()}\")\n",
    "\n",
    "if len(currently_excluded) > 0 and currently_excluded['metrics.f1squad'].notna().sum() > 0:\n",
    "    print(\"\\nExcluded no_context runs with F1 values:\")\n",
    "    print(currently_excluded[currently_excluded['metrics.f1squad'].notna()][\n",
    "        ['params.dataset_subset', 'metrics.f1squad', 'metrics.mrr', 'status']\n",
    "    ].to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
